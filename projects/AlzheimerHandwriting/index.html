<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Alzheimer's Classification | Frederik Hartmann</title> <meta name="author" content="Frederik Hartmann"> <meta name="description" content="Classification through Handwriting Analysis"> <meta name="keywords" content="Frederik, Hartmann"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://frederik-hartmann.github.io/projects/AlzheimerHandwriting/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Frederik </span>Hartmann</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Alzheimer's Classification</h1> <p class="post-description">Classification through Handwriting Analysis</p> </header> <article> <hr> <p>Authors: <a href="https://github.com/Frederik-Hartmann" rel="external nofollow noopener" target="_blank">Frederik Hartmann</a>, <a href="https://github.com/AgustinCartaya" rel="external nofollow noopener" target="_blank">Agustin Cartaya</a>, <a href="https://github.com/dagazrev" rel="external nofollow noopener" target="_blank">Jesus Gonzalez</a>, <a href="https://github.com/MicaelaRivas" rel="external nofollow noopener" target="_blank">Micaela Rivas</a> <br> Code: <a href="">Github</a></p> <p><em>This project was carried out within the scope of the Machine and Deep Learning course taught by <a href="https://scholar.google.com/citations?user=1f_f-yAAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Prof. Dr. Alessandra Scotto di Freca </a>. You can reach a detailed report <a href="">here</a>.</em></p> <p>June 2023</p> <hr> <hr> <h2 id="dataset">Dataset</h2> <p>The dataset consists of 166 observations from Alzheimer’s patients (n = 88) and healthy controls (n = 78), with 92 features per task, including patient demographics and health status. The participants perform 25 tasks in three groups (memory, copy/reverse copy, and graphic) using a graphic tablet to record pen movements. Both the pen features and the images are stored. The pen features are differentiated into in-air and on-paper. The pen features consist of features such as “mean velocity on paper” or “standard deviation of straightness error in the air”. For this project, a subset of six tasks was used to classify Alzheimer’s disease.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/task2_sample-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/task2_sample-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/task2_sample-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/task2_sample.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="task 2" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/task3_sample-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/task3_sample-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/task3_sample-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/task3_sample.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="task 3" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/task4_sample-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/task4_sample-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/task4_sample-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/task4_sample.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="task 4" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example of graphic tasks. On the left, "Join two points with a horizontal line continuously for four times". Middle: "Join two points with a vertical line continuously for four times". Right, "Retrace a 6 cm-diameter circle continuously for four times". </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/task9_sample-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/task9_sample-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/task9_sample-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/task9_sample.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="task 9" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/task10_sample-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/task10_sample-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/task10_sample-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/task10_sample.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="task 10" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example of copy tasks. On the left, "write the bigram ’le’ four times, continuously in cursive format". Right, "Copy the word "foglio" above a line". </div> <h2 id="analyzing-the-pen-features-with-machine-learning">Analyzing the pen features with Machine Learning</h2> <p>In order to classify Alzheimer’s disease, a fully automatic pipeline has been built. First, three different feature selection approaches have been performed. Second, an exhaustive search of different outlier detection techniques, feature scalers, and classifiers has been employed. Based on the cross-validation results (n = 5), the best pipeline for each classifier was chosen. Third, the hyperparameters of each classifier pipeline were tuned individually. This process was repeated for each task.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/Pipeline.svg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/Pipeline.svg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/Pipeline.svg-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/Pipeline.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="pipeline" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="analyzing-the-images-with-deep-learning">Analyzing the images with Deep Learning</h2> <p>For the classification based on the images, a transfer learning approach has been chosen. All backbone models were trained on ImageNet.</p> <ul> <li>VGG19</li> <li>ResNET50</li> <li>InceptionV3</li> <li>InceptionResnetV2</li> </ul> <p>For each of the backbone models, four different heads have been tested.</p> <ul> <li>GlobalAveragePooling2D layer, followed by a 200-dense layer with ReLU as the activation function, and one final 2-dense layer classifier based on sigmoid activation function.</li> <li>GlobalAveragePooling2D layer followed by a 256-dense layer with ReLU acti- vation function, then a 128-dense layer again with ReLU activation function, then a 64-dense layer with the ReLU activation function, and finally a 2-dense classifier layer using sigmoid as activation. </li> <li>GlobalAveragePooling2D layer, followed by a 256-dense layer with ReLU activation function, then a 0.5-dropout layer, and then a 2-dense classifier. layer with the Softmax activation function.</li> <li>Feature Extraction with Backbone Model. Classification with Machine Learning</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/projectImages/AlzheimerWriting/layers-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/projectImages/AlzheimerWriting/layers-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/projectImages/AlzheimerWriting/layers-1400.webp"></source> <img src="/assets/projectImages/AlzheimerWriting/layers.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="pipeline" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Visualisation of the third approach. </div> <p>For each of the different heads, multiple variants of unfrozen and frozen layers were tested.</p> <h2 id="results">Results</h2> <p>In the following, an example of the results is shown. For more detailed results, refer to the report.&lt;table&gt;</p> <caption>Classification using pen features results achieved with Random Forest</caption> <thead> <tr> <th></th> <th colspan="3"><strong>In Air</strong></th> <th colspan="3"><strong>On Paper</strong></th> <th colspan="3"><strong>All dataset</strong></th> </tr> <tr> <th>Task</th> <th>Full</th> <th>RF10</th> <th>RF400</th> <th>Full</th> <th>RF10</th> <th>RF400</th> <th>Full</th> <th>RF10</th> <th>RF400</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>69.8</td> <td>69.9</td> <td>72.9</td> <td>73.5</td> <td>73.5</td> <td><strong>75.3</strong></td> <td>71.7</td> <td>74.7</td> <td>71.6</td> </tr> <tr> <td>2</td> <td>72.3</td> <td>74.1</td> <td>72.3</td> <td>68.6</td> <td>71.0</td> <td>71.7</td> <td>71.1</td> <td><strong>74.7</strong></td> <td>72.3</td> </tr> <tr> <td>3</td> <td>70.5</td> <td>66.9</td> <td>71.7</td> <td>72.2</td> <td>74.0</td> <td><strong>74.1</strong></td> <td>71.1</td> <td>69.8</td> <td>70.4</td> </tr> <tr> <td>4</td> <td>68.1</td> <td>66.3</td> <td>67.4</td> <td>70.5</td> <td>71.1</td> <td>71.1</td> <td><strong>71.8</strong></td> <td>69.3</td> <td>71.7</td> </tr> <tr> <td>9</td> <td>63.2</td> <td>69.2</td> <td>68.0</td> <td>68.7</td> <td>68.7</td> <td><strong>72.9</strong></td> <td>66.2</td> <td>67.4</td> <td>69.2</td> </tr> <tr> <td>10</td> <td>68.0</td> <td>66.2</td> <td><strong>74.1</strong></td> <td>71.7</td> <td>69.8</td> <td>71.0</td> <td>70.4</td> <td>67.5</td> <td>73.5</td> </tr> </tbody> <p>&lt;/table&gt;</p> <table> <caption>CNN results for tasks 3</caption> <thead> <tr> <th>Model</th> <th>Optimizer</th> <th>Unfrozen layers</th> <th>Acc</th> <th>AUC</th> </tr> </thead> <tbody> <tr> <td>VGG19</td> <td>Adam</td> <td>2</td> <td><strong>84.0</strong></td> <td><strong>0.89</strong></td> </tr> <tr> <td>resnet50</td> <td>Adam</td> <td>3</td> <td>68.0</td> <td>0.84</td> </tr> <tr> <td>ir2</td> <td>SGD</td> <td>3</td> <td>74.0</td> <td>0.82</td> </tr> <tr> <td>inceptionv3</td> <td>SGD</td> <td>0</td> <td>74.0</td> <td>0.81</td> </tr> </tbody> </table> <table> <caption>Classifier Performance Metrics on Task 3</caption> <thead> <tr> <th><strong>Classifier</strong></th> <th><strong>RFT</strong></th> <th><strong>DTC</strong></th> <th><strong>SVM</strong></th> <th><strong>XGB</strong></th> <th><strong>MLP</strong></th> </tr> </thead> <tbody> <tr> <td>Accuracy</td> <td>0.8</td> <td>0.8</td> <td><strong>0.84</strong></td> <td>0.82</td> <td>0.76</td> </tr> <tr> <td>F1-Score</td> <td>0.814</td> <td>0.799</td> <td><strong>0.84</strong></td> <td>0.823</td> <td>0.799</td> </tr> <tr> <td>Precision</td> <td>0.814</td> <td>0.869</td> <td><strong>0.913</strong></td> <td>0.875</td> <td>0.727</td> </tr> <tr> <td>Recall</td> <td>0.814</td> <td>0.740</td> <td>0.777</td> <td>0.777</td> <td><strong>0.888</strong></td> </tr> </tbody> </table> <h2 id="conclusion">Conclusion</h2> <p>In the project, Task 1 proved challenging for comparison due to the unique nature of each sample. Writing dynamics analysis was more effective than image analysis using deep learning for this task. Signature tasks, which rely on memory, showed that learned motor patterns impact performance. For other copy tasks and graphic tasks, deep learning methods yielded better results. The study highlighted the importance of choosing the right classifier based on the task, with dynamic features suiting unique form copy tasks and deep learning features excelling in graphic and general copy tasks.</p> </article> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Frederik Hartmann. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>